#!/usr/bin/env python3
"""
LLM API ç®¡ç†å™¨æµ‹è¯•è„šæœ¬
æµ‹è¯•ä¸åŒå®¢æˆ·ç«¯çš„å·¥å…·è°ƒç”¨åŠŸèƒ½
"""

import os
import sys
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„ï¼ˆä»å½“å‰æ–‡ä»¶ä¸Šæº¯å››çº§åˆ°ä»“åº“æ ¹ç›®å½•ï¼‰
project_root = os.path.dirname(
    os.path.dirname(
        os.path.dirname(
            os.path.dirname(os.path.abspath(__file__))
        )
    )
)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from src.managers.llm_api.api_manager import LLMAPIManager

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()
    
    # å·¥å…·å®šä¹‰
    tools = [
        {
            "type": "function",
            "function": {
                "name": "web_search",
                "description": "è”ç½‘æœç´¢æœ€æ–°çš„äº‹å®ä¿¡æ¯ï¼Œå¹¶è¿”å›ç®€è¦æ‘˜è¦ä¸å…³é”®æ¥æºé“¾æ¥ã€‚",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {"type": "string", "description": "è¦æœç´¢çš„æŸ¥è¯¢è¯­å¥"},
                        "time_range": {"type": "string", "enum": ["day","week","month","year","all"], "description": "æ—¶é—´èŒƒå›´"}
                    },
                    "required": ["query"]
                }
            }
        }
    ]
    
    # æµ‹è¯•æ¶ˆæ¯
    messages = [
        {"role": "system", "content": "ä½ ç°åœ¨æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œéœ€è¦é€šè¿‡æœç´¢å·¥å…·å¸®æˆ‘è§£å†³é—®é¢˜ã€‚"},
        {"role": "user", "content": "ç¾è”å‚¨æœ€æ–°çš„æ–°é—»æœ‰å•¥ï¼Ÿä½ éœ€è¦é€šè¿‡è”ç½‘æœç´¢åå›ç­”æˆ‘ã€‚"}
    ]
    
    # ä»…æµ‹è¯•é»˜è®¤ä»é…ç½®è¯»å–çš„é€»è¾‘
    try:
        print("\nğŸ” ä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤æä¾›å•†ä¸æ¨¡å‹è¿›è¡Œæµ‹è¯•")
        manager = LLMAPIManager()
        print("âœ… å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")

        # éæµå¼è¯·æ±‚ï¼›ä¸æ˜¾å¼ä¼ å…¥ modelï¼Œåº”èµ°é»˜è®¤æ¨¡å‹
        print("ğŸ“¤ å‘é€è¯·æ±‚...")
        response = manager.chat(
            messages=messages,
            tools=tools,
            tool_choice="auto",
            temperature=0.7
        )

        if response:
            print("âœ… è¯·æ±‚æˆåŠŸ")
            print(f"ğŸ“ å“åº”ID: {response.id}")
            print(f"ğŸ¤– æ¨¡å‹: {response.model}")
            print(f"â° åˆ›å»ºæ—¶é—´: {response.created}")

            if response.choices:
                choice = response.choices[0]
                content = choice.message.content if choice.message.content else ""
                print(f"ğŸ“„ æ¶ˆæ¯å†…å®¹: {content[:200]}...")
                print(f"ğŸ å®ŒæˆåŸå› : {choice.finish_reason}")

                if choice.message.tool_calls:
                    print(f"ğŸ”§ å·¥å…·è°ƒç”¨æ•°é‡: {len(choice.message.tool_calls)}")
                    for i, tool_call in enumerate(choice.message.tool_calls):
                        print(f"   å·¥å…· {i+1}: {tool_call.get('function', {}).get('name', 'unknown')}")
                else:
                    print("ğŸ”§ æ— å·¥å…·è°ƒç”¨")

            if response.usage:
                print(f"ğŸ“Š Tokenä½¿ç”¨: {response.usage.total_tokens} (è¾“å…¥: {response.usage.prompt_tokens}, è¾“å‡º: {response.usage.completion_tokens})")
            else:
                print("ğŸ“Š æ— ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯")
        else:
            print("âŒ è¯·æ±‚å¤±è´¥: è¿”å› None")

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")

    print("-" * 50)
    
    print("\n" + "=" * 80)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 80)

if __name__ == "__main__":
    main()