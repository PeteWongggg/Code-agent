#!/usr/bin/env python3
"""
LLM API ç®¡ç†å™¨æµ‹è¯•è„šæœ¬
æµ‹è¯•ä¸åŒå®¢æˆ·ç«¯çš„å·¥å…·è°ƒç”¨åŠŸèƒ½
"""

import os
import sys
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„ï¼ˆä»å½“å‰æ–‡ä»¶ä¸Šæº¯å››çº§åˆ°ä»“åº“æ ¹ç›®å½•ï¼‰
project_root = os.path.dirname(
    os.path.dirname(
        os.path.dirname(
            os.path.dirname(os.path.abspath(__file__))
        )
    )
)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from src.managers.llm_api.api_manager import LLMAPIManager

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()
    
    # æµ‹è¯•é…ç½®
    test_configs = [
        {
            "client_name": "openai",
            "model": "gpt-4o",
            "api_key_env": "OPENAI_API_KEY"
        },
        {
            "client_name": "anthropic", 
            "model": "claude-3-5-sonnet-20241022",
            "api_key_env": "ANTHROPIC_API_KEY"
        },
        {
            "client_name": "deepseek",
            "model": "deepseek-chat",
            "api_key_env": "DEEPSEEK_API_KEY"
        },
        {
            "client_name": "openrouter",
            "model": "openai/gpt-4o",
            "api_key_env": "OPENROUTER_API_KEY"
        }
    ]
    
    # å·¥å…·å®šä¹‰
    tools = [
        {
            "type": "function",
            "function": {
                "name": "web_search",
                "description": "è”ç½‘æœç´¢æœ€æ–°çš„äº‹å®ä¿¡æ¯ï¼Œå¹¶è¿”å›ç®€è¦æ‘˜è¦ä¸å…³é”®æ¥æºé“¾æ¥ã€‚",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {"type": "string", "description": "è¦æœç´¢çš„æŸ¥è¯¢è¯­å¥"},
                        "time_range": {"type": "string", "enum": ["day","week","month","year","all"], "description": "æ—¶é—´èŒƒå›´"}
                    },
                    "required": ["query"]
                }
            }
        }
    ]
    
    # æµ‹è¯•æ¶ˆæ¯
    messages = [
        {"role": "system", "content": "ä½ ç°åœ¨æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œéœ€è¦é€šè¿‡æœç´¢å·¥å…·å¸®æˆ‘è§£å†³é—®é¢˜ã€‚"},
        {"role": "user", "content": "ç¾è”å‚¨æœ€æ–°çš„æ–°é—»æœ‰å•¥ï¼Ÿä½ éœ€è¦é€šè¿‡è”ç½‘æœç´¢åå›ç­”æˆ‘ã€‚"}
    ]
    
    print("=" * 80)
    print("LLM API å®¢æˆ·ç«¯å·¥å…·è°ƒç”¨æµ‹è¯•")
    print("=" * 80)
    
    for config in test_configs:
        client_name = config["client_name"]
        model = config["model"]
        api_key_env = config["api_key_env"]
        
        print(f"\nğŸ” æµ‹è¯•å®¢æˆ·ç«¯: {client_name.upper()}")
        print(f"ğŸ“‹ æ¨¡å‹: {model}")
        print("-" * 50)
        
        # æ£€æŸ¥APIå¯†é’¥
        api_key = os.getenv(api_key_env)
        if not api_key or api_key.startswith('your-'):
            print(f"âš ï¸  è·³è¿‡ {client_name}: æœªé…ç½® {api_key_env}")
            continue
        
        try:
            # åˆ›å»ºç®¡ç†å™¨
            manager = LLMAPIManager(
                client_name=client_name,
                stream=False,
                api_key=api_key,
                timeout=30,
                max_retries=2
            )
            
            print(f"âœ… å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            
            # æµ‹è¯•éæµå¼å“åº”
            print("ğŸ“¤ å‘é€è¯·æ±‚...")
            response = manager.chat(
                model=model,
                messages=messages,
                tools=tools,
                tool_choice="auto",
                temperature=0.7
            )
            
            if response:
                print("âœ… è¯·æ±‚æˆåŠŸ")
                print(f"ğŸ“ å“åº”ID: {response.id}")
                print(f"ğŸ¤– æ¨¡å‹: {response.model}")
                print(f"â° åˆ›å»ºæ—¶é—´: {response.created}")
                
                # æ£€æŸ¥é€‰æ‹©é¡¹
                if response.choices:
                    choice = response.choices[0]
                    content = choice.message.content if choice.message.content else ""
                    print(f"ğŸ“„ æ¶ˆæ¯å†…å®¹: {content[:200]}...")
                    print(f"ğŸ å®ŒæˆåŸå› : {choice.finish_reason}")
                    
                    # æ£€æŸ¥å·¥å…·è°ƒç”¨
                    if choice.message.tool_calls:
                        print(f"ğŸ”§ å·¥å…·è°ƒç”¨æ•°é‡: {len(choice.message.tool_calls)}")
                        for i, tool_call in enumerate(choice.message.tool_calls):
                            print(f"   å·¥å…· {i+1}: {tool_call.get('function', {}).get('name', 'unknown')}")
                    else:
                        print("ğŸ”§ æ— å·¥å…·è°ƒç”¨")
                
                # æ£€æŸ¥ä½¿ç”¨ç»Ÿè®¡
                if response.usage:
                    print(f"ğŸ“Š Tokenä½¿ç”¨: {response.usage.total_tokens} (è¾“å…¥: {response.usage.prompt_tokens}, è¾“å‡º: {response.usage.completion_tokens})")
                else:
                    print("ğŸ“Š æ— ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯")
                    
            else:
                print("âŒ è¯·æ±‚å¤±è´¥: è¿”å› None")
                
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        
        print("-" * 50)
    
    print("\n" + "=" * 80)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 80)

if __name__ == "__main__":
    main()