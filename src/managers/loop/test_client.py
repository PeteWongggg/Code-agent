import asyncio
import json
import sys
import os
from typing import List
from dotenv import load_dotenv

project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

env_path = os.path.join(project_root, '.env')
if os.path.exists(env_path):
    load_dotenv(env_path)
    print(f"âœ… å·²åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶: {env_path}")
else:
    print(f"âš ï¸  æœªæ‰¾åˆ° .env æ–‡ä»¶: {env_path}")
    print("è¯·å¤åˆ¶ env.example ä¸º .env å¹¶é…ç½®ä½ çš„ API å¯†é’¥")

from src.managers.llm_api.clients.openai.openai_client import OpenAIClient
from src.managers.llm_api.clients.anthropic.anthropic_client import AnthropicClient
from src.managers.llm_api.clients.deepseek.deepseek_client import DeepSeekClient
from src.managers.llm_api.clients.openrouter.openrouter_client import OpenRouterClient
from src.managers.llm_api.clients.private.private_client import PrivateModelClient
from src.managers.llm_api.base_client import ChatMessage, MessageRole, ChatCompletionRequest

API_KEYS = {
    "openai": os.getenv("OPENAI_API_KEY", "your-openai-api-key-here"),
    "anthropic": os.getenv("ANTHROPIC_API_KEY", "your-anthropic-api-key-here"),
    "deepseek": os.getenv("DEEPSEEK_API_KEY", "your-deepseek-api-key-here"), 
    "openrouter": os.getenv("OPENROUTER_API_KEY", "your-openrouter-api-key-here"),
    "private": os.getenv("PRIVATE_API_KEY", "EMPTY")
}

BASE_URLS = {
    "openai": os.getenv("OPENAI_BASE_URL"), 
    "anthropic": os.getenv("ANTHROPIC_BASE_URL"),
    "deepseek": os.getenv("DEEPSEEK_BASE_URL"),
    "openrouter": os.getenv("OPENROUTER_BASE_URL"),
    "private": os.getenv("PRIVATE_URL", "http://localhost:8000/v1")
}

SPECIAL_CONFIGS = {
    "openrouter": {
        "app_name": os.getenv("OPENROUTER_APP_NAME", "tokfinity-llm-client"),
        "site_url": os.getenv("OPENROUTER_SITE_URL", "https://github.com/your-repo")
    },
    "private": {
        "deployment_type": os.getenv("PRIVATE_DEPLOYMENT_TYPE", "vllm"),
        "model_name": os.getenv("PRIVATE_MODEL_NAME", "your-private-model")
    }
}

AVAILABLE_CLIENTS = {
    "openai": {
        "name": "OpenAI",
        "description": "OpenAI å®˜æ–¹ APIï¼Œæ”¯æŒ GPT ç³»åˆ—æ¨¡å‹",
        "client_class": OpenAIClient,
        "models": [
            "gpt-4-turbo-preview",
            "gpt-4",
            "gpt-3.5-turbo",
            "gpt-3.5-turbo-16k",
        ],
        "default_model": "gpt-3.5-turbo"
    },
    "anthropic": {
        "name": "Anthropic Claude",
        "description": "Anthropic çš„ Claude ç³»åˆ—æ¨¡å‹",
        "client_class": AnthropicClient,
        "models": [
            "claude-3-opus-20240229",
            "claude-3-sonnet-20240229", 
            "claude-3-haiku-20240307",
            "claude-2.1",
            "claude-2.0"
        ],
        "default_model": "claude-3-haiku-20240307"
    },
    "deepseek": {
        "name": "DeepSeek",
        "description": "DeepSeek ç³»åˆ—æ¨¡å‹ï¼Œä¸“æ³¨äºä»£ç å’Œæ¨ç†",
        "client_class": DeepSeekClient,
        "models": [
            "deepseek-chat",
            "deepseek-coder",
            "deepseek-math"
        ],
        "default_model": "deepseek-chat"
    },
    "openrouter": {
        "name": "OpenRouter",
        "description": "å¤šæ¨¡å‹èšåˆæœåŠ¡ï¼Œæ”¯æŒå¤šå®¶å‚å•†çš„æ¨¡å‹",
        "client_class": OpenRouterClient,
        "models": [
            "openai/gpt-4-turbo-preview",
            "openai/gpt-3.5-turbo",
            "anthropic/claude-3-opus",
            "anthropic/claude-3-sonnet",
            "anthropic/claude-3-haiku",
            "google/gemini-pro",
            "meta-llama/llama-2-70b-chat",
            "mistralai/mixtral-8x7b-instruct"
        ],
        "default_model": "openai/gpt-3.5-turbo"
    },
    "private": {
        "name": "ç§æœ‰åŒ–éƒ¨ç½²",
        "description": "ç§æœ‰åŒ–éƒ¨ç½²çš„æ¨¡å‹ï¼ˆvLLMã€TGIã€Ollamaç­‰ï¼‰",
        "client_class": PrivateModelClient,
        "models": [
            os.getenv("PRIVATE_MODEL_NAME", "your-custom-model"),
            "llama-2-7b-chat",
            "qwen-2.5-coder",
            "deepseek-coder",
            "codellama"
        ],
        "default_model": os.getenv("PRIVATE_MODEL_NAME", "qwen-2.5-coder")
    }
}

def create_client(client_type: str, model: str = None, api_key: str = None):
    if client_type not in AVAILABLE_CLIENTS:
        raise ValueError(f"ä¸æ”¯æŒçš„å®¢æˆ·ç«¯ç±»å‹: {client_type}")
    
    config = AVAILABLE_CLIENTS[client_type]
    
    # ä½¿ç”¨ä¼ å…¥çš„APIå¯†é’¥æˆ–é…ç½®ä¸­çš„å¯†é’¥
    if api_key is None:
        api_key = API_KEYS.get(client_type)
    
    base_url = BASE_URLS.get(client_type)
    
    if not api_key or api_key.startswith('your-'):
        print(f"âš ï¸  è­¦å‘Š: {config['name']} çš„ API å¯†é’¥æœªé…ç½®ï¼Œè¯·æ±‚å¯èƒ½ä¼šå¤±è´¥")
    
    # åˆ›å»ºå®¢æˆ·ç«¯
    client_kwargs = {
        "api_key": api_key,
        "timeout": 30
    }
    
    if base_url:
        client_kwargs["base_url"] = base_url
    
    # ç‰¹æ®Šå¤„ç†ä¸åŒå®¢æˆ·ç«¯çš„å‚æ•°
    if client_type == "openrouter":
        openrouter_config = SPECIAL_CONFIGS.get("openrouter", {})
        client_kwargs["app_name"] = openrouter_config.get("app_name", "tokfinity-examples")
        client_kwargs["site_url"] = openrouter_config.get("site_url")
    elif client_type == "private":
        private_config = SPECIAL_CONFIGS.get("private", {})
        client_kwargs["deployment_type"] = private_config.get("deployment_type", "vllm")
        if not base_url:
            client_kwargs["base_url"] = "http://localhost:8000/v1"
    
    return config["client_class"](**client_kwargs)


def test_client(client_type: str, model: str = None, test_message: str = "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚", api_key: str = None, use_stream=False, tools=None, tool_choice=None):
    config = AVAILABLE_CLIENTS.get(client_type)

    if client_type == "private":
        private_url = os.getenv("PRIVATE_URL", "http://localhost:8000/v1")
        deployment_type = os.getenv("PRIVATE_DEPLOYMENT_TYPE", "vllm")
        print(f"ğŸ  ç§æœ‰åŒ–éƒ¨ç½²ä¿¡æ¯:")
        print(f"   æœåŠ¡åœ°å€: {private_url}")
        print(f"   éƒ¨ç½²ç±»å‹: {deployment_type}")
        print(f"   æ¨¡å‹åç§°: {model}")
    
    client = create_client(client_type, model, api_key)        
    messages = [
        ChatMessage(role=MessageRole.SYSTEM, content="ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹,éœ€è¦é€šè¿‡æœç´¢å·¥å…·å¸®æˆ‘è§£å†³é—®é¢˜ã€‚"),
        ChatMessage(role=MessageRole.USER, content=test_message)
    ]
    
    request = client.create_request(
        messages=messages,
        model=model,
        temperature=0.7,
        max_tokens=200,
        stream=use_stream,
        tools=tools,
    )
            
    response = client.chat_completions_create(request)

    print(f"   å“åº”: {response}")
    
    msg = response.choices[0].message
    if getattr(msg, 'tool_calls', None):
        print(f"   æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ tool_calls: {msg.tool_calls}")
    print(f"   å†…å®¹: {msg.content}")
    
    if response.usage:
        print(f"   Tokenä½¿ç”¨: {response.usage.total_tokens} "
                f"(è¾“å…¥: {response.usage.prompt_tokens}, "
                f"è¾“å‡º: {response.usage.completion_tokens})")
    
    return True


if __name__ == "__main__":
    model_map = {
        "openai": ["gpt-4o", "gpt-4o-mini"],
        "anthropic": ["claude-3-5-sonnet-20241022", "claude-3-haiku-20240307"],
        "deepseek": ["deepseek-chat", "deepseek-reasoner"],
        "openrouter": ["openai/gpt-4o", "anthropic/claude-3-5-sonnet"],
        "private": [os.getenv("PRIVATE_MODEL_NAME", "qwen-2.5-coder")]
    }

    api_map = {
        "openai": os.getenv("OPENAI_API_KEY", "your-openai-api-key-here"),
        "anthropic": os.getenv("ANTHROPIC_API_KEY", "your-anthropic-api-key-here"),
        "deepseek": os.getenv("DEEPSEEK_API_KEY", "your-deepseek-api-key-here"),
        "openrouter": os.getenv("OPENROUTER_API_KEY", "your-openrouter-api-key-here"),
        "private": os.getenv("PRIVATE_API_KEY", "EMPTY")
    }

    client_2_use = "openrouter"       
    api_key = api_map[client_2_use]   
    model = model_map[client_2_use][0]
    use_stream=False
    
    print(f"\nğŸ” ç¯å¢ƒå˜é‡åŠ è½½çŠ¶æ€:")
    for client_id, api_key_value in api_map.items():
        status = "âœ… å·²é…ç½®" if api_key_value and not api_key_value.startswith('your-') else "âŒ éœ€è¦é…ç½®"
        print(f"   {client_id.upper()}_API_KEY: {status}")
    
    
    print(f"\nğŸ® å½“å‰æµ‹è¯•é…ç½®:")
    print(f"   å®¢æˆ·ç«¯: {client_2_use}")
    print(f"   æ¨¡å‹: {model}")
    print(f"   å¯ç”¨æ¨¡å‹: {model_map[client_2_use]}")
    print(f"   æ˜¯å¦å¯ç”¨æµå¼: {use_stream}")
    print(f"   APIçŠ¶æ€: {'âœ… å·²é…ç½®' if api_key and not api_key.startswith('your-') else 'âŒ éœ€è¦é…ç½®'}")
    
    if not api_key or api_key.startswith('your-'):
        print(f"\nâš ï¸  æç¤º: è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® {client_2_use.upper()}_API_KEY")
        print(f"   1. å¤åˆ¶ env.example ä¸º .env")
        print(f"   2. ç¼–è¾‘ .env æ–‡ä»¶ä¸­çš„ {client_2_use.upper()}_API_KEY")
    
    # å‡†å¤‡å¸¦ tools çš„æµ‹è¯•
    tools = [
        {
            "type": "function",
            "function": {
                "name": "web_search",
                "description": "è”ç½‘æœç´¢æœ€æ–°çš„äº‹å®ä¿¡æ¯ï¼Œå¹¶è¿”å›ç®€è¦æ‘˜è¦ä¸å…³é”®æ¥æºé“¾æ¥ã€‚",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {"type": "string", "description": "è¦æœç´¢çš„æŸ¥è¯¢è¯­å¥"},
                        "time_range": {"type": "string", "enum": ["day","week","month","year","all"], "description": "æ—¶é—´èŒƒå›´"}
                    },
                    "required": ["query"]
                }
            }
        }
    ]

    fed_question = "ç¾è”å‚¨æœ€æ–°çš„æ–°é—»æœ‰å•¥ï¼Ÿä½ éœ€è¦é€šè¿‡è”ç½‘æœç´¢åå›ç­”æˆ‘ã€‚"

    tools_to_use = tools
    tool_choice_to_use = "auto"

    test_client(
        client_type=client_2_use,
        model=model,
        test_message=fed_question,
        api_key=api_key,
        use_stream=use_stream,
        tools=tools_to_use,
        tool_choice=tool_choice_to_use
    )
